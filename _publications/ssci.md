---
title: "Deep Reinforcement Learning in Labor Market Simulations"
collection: publications
category: conferences
permalink: /publication/ssci
date: 2025-03-17
venue: '2025 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics (Trondheim, Norway)'
paperurl: 'https://ieeexplore.ieee.org/document/10975741'
citation: 'Chen, Ruxin; Zhang, Zeqiang. (2025). &quot;Deep Reinforcement Learning in Labor Market Simulations.&quot; <i>2025 IEEE Symposium on Computational Intelligence for Financial Engineering and Economics (CiFer)</i>. Trondheim, Norway.'
---
![Fig.](/images/ssci.jpg)


This paper proposes a novel framework for applying reinforcement learning (RL) within agent-based models (ABMs) to study labor market dynamics in labor economics. ABMs provide a flexible platform for simulating economic systems, particularly by modelling heterogeneous agents and their complex interactions, which effectively capture non-linear and emergent phenomena in labor markets. We extend an existing labor market model by integrating it into an RL framework, using the Deep Deterministic Policy Gradient (DDPG) algorithm to train agents to maximize profits, and comparing their performance with bounded-rational agents governed by predefined policies. Our findings show that RL agents, depending on the level of competition and rationality in the market, spontaneously learn distinct strategies, which significantly impact outcomes, such as unemployment and wage distribution. This work underscores the importance of ABMs in analyzing labor market dynamics and illustrates how RL-equipped agents can learn optimal strategies in evolving economic environments, offering a robust tool for policy analysis and exploring the complexities of labor market behavior.