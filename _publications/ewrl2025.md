---
title: "Learning Robust Representations for  World Models without Reward Signals"
collection: publications
category: conferences
permalink: /publication/ewrl2025
date: 2025-09-17
venue: '18th European Workshop on Reinforcement Learning (Tüebingen, Germany)'
paperurl: 'https://openreview.net/forum?id=by0V0Gk9Jj'
citation: 'Zhang, Zeqiang; Wurzberger, Fabian;  Gottwald, Sebastian; Braun, Daniel. (2024). &quot;Learning Robust Representations for  World Models without Reward Signals.&quot; <i>18th European Workshop on Reinforcement Learning</i>. Tüebingen, Germany.'
---
![Fig.](/images/ewrl2025.jpg)


Learning accurate and generalizable world models is a central challenge in model-based reinforcement learning (MBRL), particularly in reward-free settings where no task-specific supervision is available. In this paper, we investigate how different unsupervised objectives, including reconstruction, inverse dynamics, and contrastive learning, capture distinct components of the observation space, such as noise, background, controllable dynamics, and slow-changing factors. Building on this understanding, we introduce a hybrid representation learning approach that integrates the strengths of multiple objectives to better capture predictable and task-relevant structure. We design a controlled shape-based environment with disentangled latent factors to evaluate the robustness and utility of learned representations. Empirical results show that our method yields more informative and generalizable representations. 
